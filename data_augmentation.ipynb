{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581ef16-ee8a-4b16-a706-b22b4a73a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file into a DataFrame\n",
    "file_path = 'constraint-corrections-oneOf.tsv'\n",
    "\n",
    "# Assign column names\n",
    "col_names = [\n",
    "    \"constraint.statement\",\n",
    "    \"revision.id.url\",\n",
    "    \"subject.t0\", \"predicate.t0\", \"object.t0\",\n",
    "    \"follows.symbol\",\n",
    "    \"subject.t1\", \"predicate.t1\", \"object.t1\", \n",
    "    \"cud.action\",\n",
    "    \"V11\", \"V12\", \"V13\", \"V14\"\n",
    "]\n",
    "df = pd.read_csv(file_path, sep='\\t', header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4212a3c-49c7-43d9-af06-2e4e1a7c0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffe3ec-4552-4aa7-b347-b9912ee83337",
   "metadata": {},
   "source": [
    "# Extract Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528f8a9-b934-438d-b1ba-fe32d41e3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract revision_id and property_id\n",
    "df['revision_id'] = df['revision.id.url'].str.extract(r\".*/(\\d+)>\")[0]\n",
    "df['property_id'] = df['predicate.t0'].str.extract(r\".*/(P\\d+)>\")[0]\n",
    "\n",
    "# Create the result_string and initialize Full_User_URL as empty\n",
    "df['result_string'] = (\n",
    "    \"https://www.wikidata.org/w/index.php?title=Property:\" + \n",
    "    df['property_id'] + \"&oldid=\" + df['revision_id']\n",
    ")\n",
    "df['Full_User_URL'] = ''  # Initialize with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0a2c2-345a-4c6a-b858-8403ea446d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns: new columns first, followed by the rest\n",
    "new_order = ['revision_id', 'property_id', 'result_string', 'Full_User_URL'] + df.columns[:-4].tolist()\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefcd93-8ec2-4a71-b4d9-6d047282eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72047f86-28aa-48ae-bb5b-f586c59c2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Wikidata API base URL\n",
    "wikidata_api_url = \"https://www.wikidata.org/w/api.php\"\n",
    "output_file = \"users_one_of.tsv\"\n",
    "\n",
    "# Process each row and update the DataFrame\n",
    "for i in tqdm(range(len(df)), desc=\"Processing rows\"):\n",
    "    if pd.isna(df.loc[i, 'Full_User_URL']) or df.loc[i, 'Full_User_URL'] == '':\n",
    "        full_user_url = \"\"\n",
    "        revision_id = df.loc[i, 'revision_id']\n",
    "        \n",
    "        # API parameters\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'prop': 'revisions',\n",
    "            'revids': revision_id,\n",
    "            'rvprop': 'user|timestamp',\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        # Make an HTTP GET request to the API\n",
    "        response = requests.get(wikidata_api_url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            json_data = response.json()\n",
    "            \n",
    "            # Navigate through the JSON response to find the user\n",
    "            pages = json_data.get('query', {}).get('pages', {})\n",
    "            for page_id, page_data in pages.items():\n",
    "                revisions = page_data.get('revisions', [])\n",
    "                if revisions:\n",
    "                    user = revisions[0].get('user')\n",
    "                    if user:\n",
    "                        # Construct full user URL\n",
    "                        full_user_url = f\"https://www.wikidata.org/wiki/User:{user}\"\n",
    "                        \n",
    "                        # Update the DataFrame with the Full_User_URL\n",
    "                        df.at[i, 'Full_User_URL'] = full_user_url\n",
    "\n",
    "        # Simulate delay to avoid overwhelming the server\n",
    "        #if (i+1) % 1000 == 0:\n",
    "        #    time.sleep(max(1, np.random.normal(3, 1)))\n",
    "\n",
    "        # Save progress to output file periodically or after each iteration\n",
    "        if (i+1) % 1000000 == 0:\n",
    "            print(\"saving backup\")\n",
    "            df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "# Final save of the complete DataFrame to the output file\n",
    "df.to_csv(output_file, sep='\\t', index=False)\n",
    "print(\"Processing complete. Output saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcf0ec-5fa3-4e39-8444-a5d1b317fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_user_urls(df, column_name='Full_User_URL', top_n=20):\n",
    "    \"\"\"\n",
    "    Analyzes the 'Full_User_URL' column to find the top users and their share.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    user_counts = df[column_name].value_counts()\n",
    "    total_urls = len(df[column_name])\n",
    "\n",
    "    top_users = user_counts.head(top_n)\n",
    "    top_users_df = pd.DataFrame({'Count': top_users})\n",
    "    top_users_df['Share'] = top_users_df['Count'] / total_urls * 100\n",
    "\n",
    "    return top_users_df\n",
    "\n",
    "def print_top_users(df_analysis):\n",
    "    if df_analysis is None:\n",
    "        return\n",
    "    print(\"Top Users Analysis:\")\n",
    "    for user, row in df_analysis.iterrows():\n",
    "        print(f\"User: {user}, Count: {row['Count']}, Share: {row['Share']:.2f}%\")\n",
    "\n",
    "# Example usage (assuming 'df' is your DataFrame):\n",
    "# df = pd.read_csv('your_data.csv') #if reading from a file.\n",
    "\n",
    "top_users_analysis = analyze_user_urls(df) #run the analysis, and save the result.\n",
    "print_top_users(top_users_analysis) #pass the result of the analysis to the print function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
